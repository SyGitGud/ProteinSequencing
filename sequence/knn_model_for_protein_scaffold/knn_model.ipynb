{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6273a979",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Function to convert sequences to numeric representation\n",
    "def sequence_to_numeric(sequence):\n",
    "    return [CHAR_TO_INT[char] for char in sequence]\n",
    "\n",
    "# Function to convert numeric representation back to sequence\n",
    "def numeric_to_sequence(numeric_seq):\n",
    "    return \"\".join([INT_TO_CHAR[num] for num in numeric_seq])\n",
    "\n",
    "def remove_duplicate(word_list):\n",
    "    unique_words = set()\n",
    "    result = []\n",
    "\n",
    "    for word in word_list:\n",
    "        if word not in unique_words:\n",
    "            unique_words.add(word)\n",
    "            result.append(word)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_sequences(file_name):\n",
    "    sequences = []\n",
    "    lines = []\n",
    "    with open(file_name, \"r\") as input_file:\n",
    "        lines = list(filter(None, input_file.read().split(\"\\n\")))\n",
    "\n",
    "    parts = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\">\"):\n",
    "            if parts:\n",
    "                sequences.append(\"\".join(parts))\n",
    "            parts = []\n",
    "        else:\n",
    "            parts.append(line)\n",
    "    if parts:\n",
    "        sequences.append(\"\".join(parts))\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def process_data(sequences):\n",
    "    input_output_pairs = []\n",
    "    for seq in sequences:\n",
    "        for start in range(len(seq)-11):\n",
    "            end = start + 11\n",
    "            seq_in = seq[start:end]\n",
    "            temp = seq_in[0:10]+ \"-\"\n",
    "            seq_out = seq_in[10]\n",
    "            input_output_pairs.append((temp, seq_out))\n",
    "            temp = \"-\" + seq_in[1:11]\n",
    "            seq_out = seq_in[0]\n",
    "            input_output_pairs.append((temp, seq_out))\n",
    "    return input_output_pairs\n",
    "\n",
    "print(\"loading data\")\n",
    "# Load training sequences\n",
    "training_sequences = list(set(get_sequences(\"data/mab_training_sequence.txt\")))\n",
    "sequences_to_train_on = len(training_sequences)\n",
    "\n",
    "all_chars = set(\"\".join(training_sequences) + \"-\")\n",
    "NUM_CLASSES = len(all_chars)\n",
    "CHAR_TO_INT = {c: i for i, c in enumerate(all_chars, start=1)}\n",
    "INT_TO_CHAR = {v: k for k, v in CHAR_TO_INT.items()}\n",
    "with open(\"CHAR_TO_INT.txt\", \"w\") as input_file:\n",
    "    input_file.write(str(CHAR_TO_INT))\n",
    "                         \n",
    "with open(\"INT_TO_CHAR.txt\", \"w\") as input_file:\n",
    "    input_file.write(str(INT_TO_CHAR))\n",
    "\n",
    "\n",
    "X_train_data = []\n",
    "y_train_data = []\n",
    "training_seq_dict= process_data(training_sequences)\n",
    "for keys in training_seq_dict:\n",
    "    X_train_data = X_train_data + [sequence_to_numeric(keys[0])]\n",
    "    y_train_data = y_train_data + [keys[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72d60c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_model(X_train, y_train):  \n",
    "    # Train the KNN classifier\n",
    "    k = 5\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Use tqdm to visualize training progress\n",
    "    with tqdm(total=len(X_train), desc=\"TrainingSequences\") as pbar:\n",
    "        knn_classifier.fit(np.array(X_train), y_train)\n",
    "        pbar.update(len(X_train))\n",
    "\n",
    "    # Save the KNN model\n",
    "    joblib.dump(knn_classifier, 'knn_model.pkl')\n",
    "    \n",
    "    return knn_classifier\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b0ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TrainingSequences: 100%|██████████| 37425/37425 [00:00<00:00, 506354.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Accuracy : 0.9408951235804943\n",
      "testing Accuracy : 0.9225775426785285\n"
     ]
    }
   ],
   "source": [
    "#data split\n",
    "max_seq_length = max(len(seq) for seq in X_train_data)\n",
    "\n",
    "# Pad training sequences to the same length\n",
    "padded_training_sequences_numeric = [seq + [0] * (max_seq_length - len(seq)) for seq in X_train_data]\n",
    "\n",
    "X_train = np.array(padded_training_sequences_numeric)\n",
    "y_train = np.array(y_train_data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "knn_model = KNN_model(X_train,y_train)\n",
    "\n",
    "predicted_labels = knn_model.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, predicted_labels)\n",
    "print(\"training Accuracy :\", accuracy_train)\n",
    "y_pred = knn_model.predict(X_val)\n",
    "accuracy =  accuracy_score(y_val, y_pred)\n",
    "print(\"testing Accuracy :\",accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c2bf0",
   "metadata": {},
   "source": [
    "<h2>Prediction and Gap Filling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a01250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAR_TO_INT: {'T': 1, 'R': 2, 'L': 3, 'Y': 4, 'E': 5, 'A': 6, 'K': 7, 'W': 8, '-': 9, 'I': 10, 'C': 11, 'G': 12, 'H': 13, 'P': 14, 'Q': 15, 'V': 16, 'F': 17, 'S': 18, 'M': 19, 'N': 20, 'D': 21}\n",
      "INT_TO_CHAR: {1: 'T', 2: 'R', 3: 'L', 4: 'Y', 5: 'E', 6: 'A', 7: 'K', 8: 'W', 9: '-', 10: 'I', 11: 'C', 12: 'G', 13: 'H', 14: 'P', 15: 'Q', 16: 'V', 17: 'F', 18: 'S', 19: 'M', 20: 'N', 21: 'D'}\n"
     ]
    }
   ],
   "source": [
    "#load trained model\n",
    "import joblib\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Load the saved KNN model\n",
    "knn_classifier = joblib.load('knn_model.pkl')\n",
    "\n",
    "with open(\"CHAR_TO_INT.txt\", \"r\") as char_to_int_file:\n",
    "    CHAR_TO_INT = ast.literal_eval(char_to_int_file.read())  # Load dictionary from file\n",
    "\n",
    "with open(\"INT_TO_CHAR.txt\", \"r\") as int_to_char_file:\n",
    "    INT_TO_CHAR = ast.literal_eval(int_to_char_file.read())  # Load dictionary from file\n",
    "\n",
    "print(\"CHAR_TO_INT:\", CHAR_TO_INT)\n",
    "print(\"INT_TO_CHAR:\", INT_TO_CHAR)\n",
    "\n",
    "def sequence_to_numeric(sequence):\n",
    "    return [CHAR_TO_INT[char] for char in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2f55911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sequence for De Novo: DIQMTQSPSSLSASVGDRVTITCKASQNIDKYLNWYQQKPGKAPKLLIYNTNNLQTGVPSRFSGSGSGTDFTFTISSLQPEDIATYYCLQHISRPRTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\n"
     ]
    }
   ],
   "source": [
    "#gap filling\n",
    "\n",
    "#mabcampath scaffold\n",
    "de_novo_sequence = \"---MTQSPSSLSASVGDRVTITCK---NIDKYLNWYQQKPGKAPKLLIYNTNNLQTGVPS\\\n",
    "RF---G----FTFTI-----------YCLQHISRPRTFGQGTKVEIKRTVAAPSVFIFPP\\\n",
    "SDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLT\\\n",
    "LSKADYEKHKVYACEVTHQGLSSPVTKSFN----\"\n",
    "\n",
    "new_seq = []\n",
    "for count,  i in enumerate(range(len(de_novo_sequence) - 11 + 1)):\n",
    "    kmer = de_novo_sequence[i:i + 11]\n",
    "    new_seq = new_seq + [kmer]\n",
    "\n",
    "while \"-\" in de_novo_sequence:\n",
    "    keys_with_dash = [key for key in new_seq if key.count('-') == 1]\n",
    "    if len(keys_with_dash) == 0:\n",
    "        keys_with_dash = [key for key in new_seq if key.count('--') == 2]\n",
    "    for k in keys_with_dash:\n",
    "        if k[0] == \"-\" or k[10] == \"-\":\n",
    "            if k in de_novo_sequence:\n",
    "                \n",
    "                # Convert de novo sequence and its reverse to numeric representation\n",
    "                de_novo_sequence_numeric = sequence_to_numeric(k)\n",
    "\n",
    "                X_de_novo = np.array([de_novo_sequence_numeric])\n",
    "                # Make predictions for the de novo sequence reverse\n",
    "                y_pred_de_novo = knn_model.predict(X_de_novo)\n",
    "                # Convert the predicted labels back to sequences for verification\n",
    "                predicted_value = y_pred_de_novo[0]\n",
    "                index = de_novo_sequence.index(k)\n",
    "                index1 = k.index(\"-\")\n",
    "                if 0 <= (index + index1) < len(de_novo_sequence):\n",
    "                    de_novo_sequence = de_novo_sequence[:(index + index1)] + predicted_value +de_novo_sequence[(index + index1) + 1:]\n",
    "\n",
    "            # Update new_seq after filling a gap\n",
    "                new_seq.clear()\n",
    "                for count, i in enumerate(range(len(de_novo_sequence) - 11 + 1)):\n",
    "                    kmer = de_novo_sequence[i:i + 11]\n",
    "                    new_seq = new_seq + [kmer]\n",
    "                keys_with_dash = [key for key in new_seq if key.count('-') == 1]\n",
    "                if len(keys_with_dash) == 0:\n",
    "                    keys_with_dash = [key for key in new_seq if key.count('--') == 2]\n",
    "        \n",
    "# Print the predicted sequence for the de novo sequence\n",
    "print(\"Predicted Sequence for De Novo:\", de_novo_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_color(s, color):\n",
    "    \"\"\"Wrap string in ANSI color codes for terminal display.\"\"\"\n",
    "    colors = {\n",
    "        \"black\": \"\\033[30m\",   # Black text\n",
    "        \"green\": \"\\033[32m\",   # Green text\n",
    "        \"red\": \"\\033[31m\",     # Red text\n",
    "        \"reset\": \"\\033[0m\"     # Reset to default\n",
    "    }\n",
    "    return f'{colors[color]}{s}{colors[\"reset\"]}'\n",
    "\n",
    "def compare_sequences(target, denovo, predicted):\n",
    "    \"\"\"Compare target, denovo, and predicted sequences and assign colors based on conditions.\"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for t, d, p in zip(target, denovo, predicted):\n",
    "        if t == d == p:\n",
    "            result.append(add_color(p, \"reset\"))  \n",
    "        elif t == p and t != d:\n",
    "            result.append(add_color(p, \"green\"))  \n",
    "        else:\n",
    "            result.append(add_color(p, \"red\"))  \n",
    "\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "predicted = de_novo_sequence\n",
    "\n",
    "target = \"DIQMTQSPSSLSASVGDRVTITCKASQNIDKYLNWYQQKPGKAPKLLIYNTNNLQTGVPS\\\n",
    "RFSGSGSGTDFTFTISSLQPEDIATYYCLQHISRPRTFGQGTKVEIKRTVAAPSVFIFPP\\\n",
    "SDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLT\\\n",
    "LSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\"\n",
    "\n",
    "scaffold = \"---MTQSPSSLSASVGDRVTITCK---NIDKYLNWYQQKPGKAPKLLIYNTNNLQTGVPS\\\n",
    "RF---G----FTFTI-----------YCLQHISRPRTFGQGTKVEIKRTVAAPSVFIFPP\\\n",
    "SDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLT\\\n",
    "LSKADYEKHKVYACEVTHQGLSSPVTKSFN----\"\n",
    "\n",
    "\n",
    "colored_predicted = compare_sequences(target, scaffold, predicted)\n",
    "print(scaffold)\n",
    "print(colored_predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
